{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c5a2ed0",
      "metadata": {},
      "source": [
        "## 0) Imports & Setup\n",
        "We load libraries and configure the Gemini client. For safety, the API key is read from the `GEMINI_API_KEY` environment variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5a8fe9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Read API key from environment for safety (keeps the variable name API_KEY)\n",
        "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "print(\"GEMINI_API_KEY set:\", bool(API_KEY))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ee2d4a",
      "metadata": {},
      "source": [
        "## 1) Configuration (repo-relative paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c63d36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURATION ===\n",
        "INPUT_CSV = r\"../../../data/electoralTerm_19.csv\"  # repo-relative path\n",
        "OUTPUT_CSV = r\"../../../data/electoralTerm_19_scored_gemini_2_5.csv\"  # repo-relative path\n",
        "CHUNK_SIZE = 500\n",
        "MODEL_NAME = \"gemini-2.5-flash-lite\" # change model if needed \n",
        "SLEEP_BETWEEN_REQUESTS = 0.5  # adjust if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeace078",
      "metadata": {},
      "source": [
        "## 2) Initialize Gemini\n",
        "Configures the Gemini client with your key and creates the model object.\n",
        "This keeps your original variable names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1109ce51",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Initialize Gemini ===\n",
        "if not API_KEY:\n",
        "    raise RuntimeError(\n",
        "        \"GEMINI_API_KEY is not set. Please set it in your environment before running this cell.\"\n",
        "    )\n",
        "genai.configure(api_key=API_KEY)\n",
        "model = genai.GenerativeModel(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0105cd70",
      "metadata": {},
      "source": [
        "## 3) Load Data\n",
        "Reads the CSV to `df` and adds a `custom_id` column to preserve original indexing for joins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22a1c7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Load Data ===\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "df['custom_id'] = df.index.astype(str)\n",
        "print(f\"üìÑ Loaded {len(df)} rows from {INPUT_CSV}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78244dd8",
      "metadata": {},
      "source": [
        "## 4) Load Existing Results (if any)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c65f0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Load existing results if available ===\n",
        "if os.path.exists(OUTPUT_CSV):\n",
        "    existing_df = pd.read_csv(OUTPUT_CSV)\n",
        "    if 'gemini_score' in existing_df.columns:\n",
        "        df['gemini_score'] = existing_df['gemini_score']\n",
        "    else:\n",
        "        df['gemini_score'] = pd.NA\n",
        "else:\n",
        "    df['gemini_score'] = pd.NA\n",
        "\n",
        "# Optional: save a safety snapshot of current df state\n",
        "# df.to_csv(OUTPUT_CSV, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbda201",
      "metadata": {},
      "source": [
        "## 5) Prompt Template\n",
        "Builds the classification instruction for each `speechContent` text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba706480",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Prompt template ===\n",
        "def build_prompt(text):\n",
        "    return f\"\"\"You are a political analyst trained to classify political texts on a 1-10 left-right ideological spectrum. Your task is to read a political speech or excerpt and assign a number from 1 (far-left) to 10 (far-right) based on its ideological content.\n",
        "\n",
        "\n",
        "Use this scale as a reference, based on common positions in German politics:\n",
        "\n",
        "\n",
        "1: Far-left, revolutionary socialism (e.g., MLPD, Antifa)  \n",
        "2: Anti-capitalist democratic socialism (e.g., DIE LINKE, radical wing)  \n",
        "3: Progressive left, social justice-focused (e.g., DIE LINKE, moderate)  \n",
        "4: Center-left, reformist social democracy (e.g., SPD)  \n",
        "5: Centrist, socially liberal or pragmatic (e.g., Volt, FDP, left-liberal)  \n",
        "6: Center-right liberalism, market-oriented (e.g., FDP, neoliberal wing)  \n",
        "7: Conservative mainstream (e.g., CDU/CSU)  \n",
        "8: National-conservative or traditionalist right (e.g., WerteUnion)  \n",
        "9: Right-wing populist, anti-immigration (e.g., AfD, moderate)  \n",
        "10: Far-right nationalist or extremist (e.g., AfD, radical wing)\n",
        "\n",
        "\n",
        "Classify the following political text according to this scale and output **only the numeric value (1-10)**. Do not add explanations, comments, or any additional text.\n",
        "\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33409f89",
      "metadata": {},
      "source": [
        "## 6) Process in Chunks & Save Progress\n",
        "Iterates the dataset in `CHUNK_SIZE` blocks, queries Gemini, parses a numeric score, and writes progress to CSV after each chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4615f1ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Process Remaining Entries Only ===\n",
        "for i in tqdm(range(0, len(df), CHUNK_SIZE), desc=\"üîÑ Processing chunks\"):\n",
        "    chunk = df.iloc[i:i + CHUNK_SIZE]\n",
        "\n",
        "    for idx, row in chunk.iterrows():\n",
        "        if pd.notna(row['gemini_score']):\n",
        "            continue  # already done, skip\n",
        "\n",
        "        prompt = build_prompt(row['speechContent'])\n",
        "\n",
        "        try:\n",
        "            response = model.generate_content(prompt, generation_config={\"temperature\": 0.05})\n",
        "            score = response.text.strip()\n",
        "            score = ''.join(filter(str.isdigit, score))\n",
        "            if score.isdigit():\n",
        "                df.at[idx, 'gemini_score'] = int(score)\n",
        "            else:\n",
        "                df.at[idx, 'gemini_score'] = None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error on row {idx}: {e}\")\n",
        "            df.at[idx, 'gemini_score'] = None\n",
        "\n",
        "        time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
        "\n",
        "    # ‚úÖ Save progress after each chunk\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"üíæ Progress saved after chunk ending at row {i + CHUNK_SIZE}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
